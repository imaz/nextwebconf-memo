WebRTC

WebRTCとは、ビデオや音声、データをブラウザ間でやり取り可能にする規格です（RTCは「Real-Time Communication」の略）。 WebRTCの機能を利用することで、Webサイト上でビデオ・音声チャットやファイルをやり取りできます。

    へぇ〜

過去の遺産を引きずっているのをWebであわせていかなきゃいけない
非常に多くの知識が要求される
つらい話


JS(クライアント側)で頑張って吸収する
全ブラウザが6週間くらい更新している？
Chromeの46に上げた途端に繋がらなくなる 勝手に！
WebRTCの一番ツライところ

運用する人がカバーしなきゃいけない

JavaScriptのツライ話
  カバーできないのでいらない

運用のツライ話から
  SDP? candidate が読めないとお話にならない
  WS XHR つながらないというのはわかる WebRTC だけはつながらないみたいなことがある
  お客様の環境でつながらないといわれる 手元にあるのはcandidateだけ
レイテンシーのツライ話
  UDPパケットがロストした時点で動画の質が落ちる
  P2Pでやるとかなっちゃう？
  どれくらいつながらないか
    ネットワークがちゃんとしてれば繋がる
    LTE 3GP とかはまあほぼ繋がる
    UDPが抜けない人たち？
  動画音声をTCP経由でやり取りしなきゃいけないとなると結局サーバ経由になってしまう
  （WebRTCってサーバ経由じゃないの!?）
  "データをブラウザ間でやりとり可能にする" か…!!

  SDPを読める人は運用状態に入ると占有されるので開発とかできない
  ChromeとFireFoxで投げてくるSDPがまったく別 Chromeは古くて全然最先端に追従してくれない
  hangoutの足かせはそんなにデカイのか？
    実際はどうかなあ でもhangout動かなくなるとすごい
    リアルタイム配信とかは利権がすごい世界
    Googleの戦略としては正しい（困るのは我々だけ）

  ORTC
    WebRTCの次世代
    WebRTCのSDPとかツライよねっていうのでJSONになったけど仕様がめっちゃフクザツになった
    ドラスティックな未来がみえる
      ナントカのAPIが出てる
    ORTCを使ったWebRTC以外のライブラリがでてきそう

    V < 僕は全然期待してなくて
    ｗｗｗ

    MicrosoftはSkypeのためにやってるのであんまり前に倣う感じがない

    なんかこういう動画の形式がある
      VP8 VP9
      H264UC
        Skype でしか使えない エッジでしか使えない技術は意味がない

    何が本当にできるのかわからない
    のってきたところで仕様でできるはずのことがどこまでほんとうにできるのか
    間に人が入って隣の人に転送するとかいうのはできそうな雰囲気がある
    それができるとリアコネクション？ハブアンドスポークにするとか
    飛行機ネットワークみたいなものが組めたら楽しそうだなって

  RTPsender Recieverみたいな
    getしかできない 書き込みとかできません
    js力 1.0を決めようというのが 10月末とか11月上旬にあって（あれ札幌でやるやつか？）
  WebRTC残念
  1個しか動画の画質を送れない
  ブラウザ間通信で相手の回線も同じだけ専用する
  サイマルキャスト
    高画質と低画質で配信をわけられる
    Chromeは対応済み
    Google特殊なナントカを書かないと実装されない
    WebRTCはP2Pでいいよね

    MCU
      サーバがトランスポートする
        たとえば複数人レコードしたのを合成してひとつのフレームにしたうえで受信者に配信する
        純粋に見る人が多くても大丈夫になる 100人とか単位でも
      1つのエンコードの結果は1つ
      画質がめっちゃ悪くなる 細い人に
      低高画質両方エンコードすれば？
        動画変換はすっごいリソースくうのでツライやつ
      この先はMCUを作ってる人が相当頑張らないと、GPU使うMCUがもとめられている
      現在はサイマルキャストがない世界では最適解

    大企業でつかうにはMCUでよさ気

    SFU
      再変換しない　全てのパケットをサーバに送ってサーバが配布する
      パケットを左から貰って右に投げてるだけ
      動画変換がないけど、重いところは暗号化
      100人に対して全員別の鍵で暗号化して復号化しておくってみたいなのする

    SFUとMCUを使わない限りはサーバサイドで録画ができない
      合成されてないので合成するっていう処理が必要
      合成状態で録画するっていうのはそれ専用のサーバが必要
      参加タイミングがバラバラなのに時間軸をあわせあきゃいけない

    RTP RTCP 暗号化してる
      WebRTC=RTCPなんじゃないかと思ってて ｗｗｗ←!?

      動画はUTPなのでロストする
      ロストを補完するにはなにをロストしているか知らなきゃいけない
      SFAの場合は1:n n人が別のところにブロックノイズをかける
      SFU経由で全員に配られる
      全員から送られてきたビットレートでRTCPを見ながらみんなの回線を推定してこれくらいのデータで送ってくれっていう
      よくわかんない話になったな！

    MCU
      定期的にビットレート送ってる
      3秒間ずれたら待ってくれよっていう感じ

    おもしろいなー動画規格で遊ぶ P2P たりなくなる

クライアントの話
  ChromeVersion固定が現実解
    NativeChromeLibrary クライアントバージョン固定できます
    P2Pでふたつつなぐ場合に関してはその2人だけつながれば良いわけで
  iOSのVersionとかは制御できない
  HTMLでできたサービスを提供しない

  世界は閉じたつもりでいてもどこかで隙間があいている

  FireFoxのコードはきれい　へぇ〜

  LibWebRTC ここにこれまとまってるんだーくらいの感覚

  electron
    なんとかベースなのでVersionが固定される
    閉ざされた環境が作り放題！
    electron のとこにもWebRTC使ったアプリがupされてるくらい

  組み込み ラズパイとか
    ラズパイ２めっちゃはやい
    ハードウェアエンコーダを最初から積んでるめっちゃいい
    暗号化はべつ　クライアントだけかとそんなに重くなくて2,30%で
    エンコードはハードウェアエンコードをいかに使うかが鍵？
      OpenGLみたいな標準化しようとしているけど
      < 今Webの話してますからね
    ラズパイ4core!! 3人くらい動画通信できるかも
    エンコードは共有されるからもうちょっと増えるかも

  規格が色々ばらけてるけどOpenである
    WebRTC使ってハードに組み込んだ場合ライセンス料とかかからない

  V6が普及するとNatはいらないとかいうけどそんなことない
  この辺の話まったくわからんぞ！！
  ChromeはcnadidateでV6返してくるけどね

  MCU SFU 一つのハードから回線複数に配信することにはいかない
  結局サーバを超えなければいけないのではないかって感じ
  じゃあP2Pでがんばるの？
    フルメッシュってなんだろう

  組み込みでSFU/MCUを使わないっていう選択肢はない
  クライアントサイドに録画するというの組み込みでは考えられない
  結局サーバ側でほどかなきゃいけないので

  ブラウザでみれて
  WebRCUをさわることはない？
  コストがかかるから自分たちがやるぜって選択肢ある


ツライ話は運用だけで使う側はそんな辛くない
  WebRTCでビジネスとかはむずい
  WebRTCを使って既存ビジネスを便利にする

ORTCは人が扱えるAPIじゃない
  AdapterJSを世界中の誰かが作ってくれるからそれ使ってwrapとかでしようね

ツライ部分はSDK作ってる人が

つながらないのはLANケーブル抜けてるときｗｗ

candidate揃ってるのになんでつながらないんだ！
  RTP Timeoutってでてた
  P2P LANがきれてもホストのcandidateサクセスみたいなのみえちゃう？ふん？

  private型のtop box
  VM1個提供しててそこにアクセスするとできるよってやつ

  リモート
  WebRTC sygnaling server
  運用者が叩けるAPIがほしいね

WebRTC 通信全部暗号化されている
  キャプチャするぞ！ wiresharkたちあげる
  セッションキーとりだせばいいんだ！
  DTSLSRTPっていう特殊な暗号化を使ってる
    基本みれない
  パケット見れない何が起きてるかわからない
    基本的にサーバ経由するしかないのだ
  P2Pはサーバわざわざ経由しなくていいというだけのこと

最初P2PでつなごうとしていてだめだったらSPU?とかでっていう発想がおおいけど逆かなって
FBとかはSFU?で繋いでP2PできそうだったらP2Pに落とすとかいうのをやってる

P2PからMCUにかわるっていうモデル
  polycom? WebRTCのpolycom?版ができた
  少人数はP2P
  3人とか4人になった瞬間、モバイル機器が入った瞬間にMCUになる
  表示人数分デコーダをまわさなきゃいけない
  MCUはデコードするのは1個分でいい モバイル うおーなんかわかってきた気がするぞ！

SVC
  サイマルキャストは低高画質１個ずつをつくらなきゃいけない
  SVCは高画質から低画質を生成することができる
  Googleがやるよっていってくれてる
  SMUやMCUがうまく振り分けて

SVCのRFCはH264ででている
SFUは codec war になる
  高画質から低画質を抽出する方法が VP9 H264 でちがう

ブラウザサイドのブラウザバージョンアップについてくのがつらい
SFU MCU つくってる人がいちばんつらい
Chromeのバージョンアップつらいよね っていうと仲よくなれるｗｗｗ

SFU買わなきゃダメですよ?? SFUって買うものなのか!?

SVCツライよ?
クライアントツライ

SFU Selective
  SFU SDK でgithub検索しよう！
  複数を束ねるコーディング？

